{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0ae3a07",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92b847d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from torch import nn\n",
        "import torch\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b655998",
      "metadata": {},
      "source": [
        "# File Path Declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bca2318a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project_base_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))))\n",
        "project_base_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a63ba52c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON/data/generation/yara/yara-rules_v1.pkl'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_v1_generated_data_path = os.path.join(project_base_path, \"data/generation/yara/yara-rules_v1.pkl\")\n",
        "saved_v1_generated_data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e67bc246",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON/data/generation/yara/yara-rules_v2.pkl'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_v2_generated_data_path = os.path.join(project_base_path, \"data/generation/yara/yara-rules_v2.pkl\")\n",
        "saved_v2_generated_data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b39cddc9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON/results/LLM_Rule_GtRule/quantitative/yara/gpt_4o'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_rule_dir_path = os.path.join(project_base_path, \"results/LLM_Rule_GtRule/quantitative/yara/gpt_4o\")\n",
        "generated_rule_dir_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae2ac23f",
      "metadata": {},
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a196de70",
      "metadata": {},
      "outputs": [],
      "source": [
        "open_ai_key = \"OPENAI_KEY\"\n",
        "client = OpenAI(api_key=open_ai_key)\n",
        "open_ai_model_name = \"gpt-4o\"\n",
        "SEED = 42\n",
        "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
        "MAX_LEN = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4c800994",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_open_ai_response(prompt: str, model_name: str = open_ai_model_name) -> str:\n",
        "\n",
        "  # Set the client with API key\n",
        "  client = OpenAI(\n",
        "    api_key=open_ai_key,  # This is the default and can be omitted\n",
        "  )\n",
        "\n",
        "  try:\n",
        "      # Call the OpenAI API\n",
        "      chat_completion = client.chat.completions.create(\n",
        "          messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}],\n",
        "          model=model_name\n",
        "      )\n",
        "\n",
        "      # Extract and return the assistant's reply\n",
        "      return chat_completion.choices[0].message.content\n",
        "\n",
        "  except Exception as e:\n",
        "      return f\"@@$$## Error communicating with OpenAI API: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "df21a1b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Hello! I am based on OpenAI's GPT-4.0 architecture. How can I assist you today?\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_open_ai_response(\"Hello, which gpt version are you?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2eecd5a",
      "metadata": {},
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2688f6b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_from_pickle(file_path) -> dict:\n",
        "    \"\"\"\n",
        "    Loads data from a pickle file.\n",
        "\n",
        "    :param file_path: Path to the pickle file\n",
        "    :return: Loaded data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            return pickle.load(file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data from pickle: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "108855cf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_first_n_elements(dictionary: dict, n: int) -> dict:\n",
        "    \"\"\"\n",
        "    Get the first n elements of a dictionary.\n",
        "\n",
        "    :param dictionary: The input dictionary\n",
        "    :param n: The number of elements to retrieve\n",
        "    :return: A dictionary with the first n elements\n",
        "    \"\"\"\n",
        "    return dict(list(dictionary.items())[:n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "607be793",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_string_as_txt(directory_path, file_name, content):\n",
        "    \"\"\"\n",
        "    Saves a given string as a .txt file in the specified directory.\n",
        "\n",
        "    Args:\n",
        "        directory_path (str): Path to the directory where the file should be saved.\n",
        "        file_name (str): Desired name of the file (with or without .txt extension).\n",
        "        content (str): The string content to be written to the file.\n",
        "\n",
        "    Returns:\n",
        "        str: Full path to the saved file if successful, otherwise an empty string.\n",
        "    \"\"\"\n",
        "    if not file_name.lower().endswith('.txt'):\n",
        "        file_name += '.txt'\n",
        "    \n",
        "    file_path = os.path.join(directory_path, file_name)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(directory_path, exist_ok=True)  # Create directory if it doesn't exist\n",
        "        with open(file_path, 'w', encoding='utf-8') as file:\n",
        "            file.write(content)\n",
        "        return file_path\n",
        "    except PermissionError:\n",
        "        print(f\"Error: Permission denied to write to '{file_path}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving the file: {e}\")\n",
        "\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90dbbae2",
      "metadata": {},
      "source": [
        "# Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9337acae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4588\n"
          ]
        }
      ],
      "source": [
        "# Load the data back from the pickle file\n",
        "loaded_v1_data = load_from_pickle(saved_v1_generated_data_path)\n",
        "print(len(loaded_v1_data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "d6476eea",
      "metadata": {},
      "outputs": [],
      "source": [
        "yara_cti_sample_dict = get_first_n_elements(loaded_v1_data, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "063193a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4587\n"
          ]
        }
      ],
      "source": [
        "# Load the data back from the pickle file\n",
        "loaded_v2_data = load_from_pickle(saved_v2_generated_data_path)\n",
        "print(len(loaded_v2_data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "1ce0991b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rule MSIETabularActivex\\n{\\n        meta:\\n                ref = \"CVE-2010-0805\"\\n                impact = 7\\n                hide = true\\n                author = \"@d3t0n4t0r\"\\n        strings:\\n                $cve20100805_1 = \"333C7BC4-460F-11D0-BC04-0080C7055A83\" nocase fullword\\n                $cve20100805_2 = \"DataURL\" nocase fullword\\n                $cve20100805_3 = \"true\"\\n        condition:\\n                ($cve20100805_1 and $cve20100805_3) or (all of them)\\n}': 'Rule Name\\n  MSIETabularActivex\\n\\nDescription\\n  This YARA rule detects a specific vulnerability (CVE-2010-0805) associated with an ActiveX control. The rule targets potentially malicious strings that could be used in exploit attempts related to this vulnerability.\\n\\nReference\\n  CVE-2010-0805\\n\\nIndicators / String Matches\\n  This rule matches the following strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $cve20100805_1\\t\"333C7BC4-460F-11D0-BC04-0080C7055A83\"\\tActiveX control CLSID\\n  $cve20100805_2\\t\"DataURL\"\\tPossible exploit-related term\\n  $cve20100805_3\\t\"true\"\\tPotential Boolean indicator used in exploitation\\n\\n  All string patterns use nocase and fullword modifiers, allowing detection regardless of case and requiring exact word matches.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  The ActiveX control CLSID ($cve20100805_1) and the Boolean indicator ($cve20100805_3) are both present.\\n\\n  Alternatively, if all strings ($cve20100805_1, $cve20100805_2, and $cve20100805_3) are found.',\n",
              " 'rule Contains_VBA_macro_code\\n{\\n\\tmeta:\\n\\t\\tauthor = \"evild3ad\"\\n\\t\\tdescription = \"Detect a MS Office document with embedded VBA macro code\"\\n\\t\\tdate = \"2016-01-09\"\\n\\t\\tfiletype = \"Office documents\"\\n\\n\\tstrings:\\n\\t\\t$officemagic = { D0 CF 11 E0 A1 B1 1A E1 }\\n\\t\\t$zipmagic = \"PK\"\\n\\n\\t\\t$97str1 = \"_VBA_PROJECT_CUR\" wide\\n\\t\\t$97str2 = \"VBAProject\"\\n\\t\\t$97str3 = { 41 74 74 72 69 62 75 74 00 65 20 56 42 5F } // Attribute VB_\\n\\n\\t\\t$xmlstr1 = \"vbaProject.bin\"\\n\\t\\t$xmlstr2 = \"vbaData.xml\"\\n\\n\\tcondition:\\n\\t\\t($officemagic at 0 and any of ($97str*)) or ($zipmagic at 0 and any of ($xmlstr*))\\n}': '    Rule Name\\n        Contains_VBA_macro_code\\n    \\n    Description\\n        This YARA rule is designed to detect Microsoft Office documents that contain embedded VBA macro code. Macros are often used by attackers to execute malicious actions in the context of Office applications. The rule checks both OLE and Open XML format documents for indications of VBA content.\\n    \\n    Indicators / String Matches\\n        This rule uses the following string patterns to identify potential VBA macro content:\\n    \\n        String ID\\tPattern\\t                        Notes\\n        $officemagic\\t{ D0 CF 11 E0 A1 B1 1A E1 }\\tOLE file format magic number\\n        $zipmagic\\t\"PK\"\\t                        ZIP file format magic number (indicative of Office Open XML)\\n        $97str1\\t    \"_VBA_PROJECT_CUR\" wide       \\tIdentifies VBA project storage in OLE documents\\n        $97str2\\t    \"VBAProject\"\\t                VBA project stream name\\n        $97str3\\t    { 41 74 74 72 69 62 75 74 00 65 20 56 42 5F }\\tRepresents \"Attribute VB_\"\\n        $xmlstr1\\t\"vbaProject.bin\"\\t            VBA project container file in ZIP format\\n        $xmlstr2\\t\"vbaData.xml\"\\t                XML file containing VBA data\\n    \\n    Condition Logic\\n        The rule triggers if:\\n    \\n        - The file is an OLE document (identified by $officemagic at offset 0) and contains any of the VBA-related patterns ($97str1, $97str2, or $97str3).\\n    \\n        - The file is a ZIP (Office Open XML) document (identified by $zipmagic at offset 0) and contains any of the XML-based VBA indicators ($xmlstr1 or $xmlstr2).',\n",
              " 'rule php_anuna\\n{\\n    meta:\\n        author      = \"Vlad https://github.com/vlad-s\"\\n        date        = \"2016/07/18\"\\n        description = \"Catches a PHP Trojan\"\\n    strings:\\n        $a = /<\\\\?php \\\\$[a-z]+ = \\'/\\n        $b = /\\\\$[a-z]+=explode\\\\(chr\\\\(\\\\([0-9]+[-+][0-9]+\\\\)\\\\)/\\n        $c = /\\\\$[a-z]+=\\\\([0-9]+[-+][0-9]+\\\\)/\\n        $d = /if \\\\(!function_exists\\\\(\\'[a-z]+\\'\\\\)\\\\)/\\n    condition:\\n        all of them\\n}': \"```\\nRule Name\\n  php_anuna\\n\\nDescription\\n  This YARA rule is designed to detect a specific PHP Trojan by identifying suspicious script patterns typical of malicious PHP code. The trojan employs obfuscation techniques such as variable assignment through code evaluation and uses checks for undefined functions.\\n\\nIndicators / String Matches\\n  This rule matches the following regular expressions:\\n\\n  String ID\\tPattern\\tNotes\\n  $a\\t/<\\\\?php \\\\$[a-z]+ = '/\\tDetects PHP code starting with variable assignment\\n  $b\\t/\\\\$[a-z]+=explode\\\\(chr\\\\(\\\\([0-9]+[-+][0-9]+\\\\)\\\\)/\\tDetects obfuscated explode calls\\n  $c\\t/\\\\$[a-z]+=\\\\([0-9]+[-+][0-9]+\\\\)/\\tDetects arithmetic operations in obfuscated variables\\n  $d\\t/if \\\\(!function_exists\\\\('[a-z]+'\\\\)\\\\)/\\tChecks for the use of function_exists in obfuscation\\n\\nCondition Logic\\n  The rule triggers if all of the specified string patterns ($a through $d) are found within the PHP file, indicating potential obfuscated malicious activity.\\n\\n```\",\n",
              " 'rule Powerkatz_DLL_Generic {\\n\\tmeta:\\n\\t\\tdescription = \"Detects Powerkatz - a Mimikatz version prepared to run in memory via Powershell (overlap with other Mimikatz versions is possible)\"\\n\\t\\tauthor = \"Florian Roth\"\\n\\t\\treference = \"PowerKatz Analysis\"\\n\\t\\tdate = \"2016-02-05\"\\n\\t\\tsuper_rule = 1\\n\\t\\tscore = 80\\n\\t\\thash1 = \"c20f30326fcebad25446cf2e267c341ac34664efad5c50ff07f0738ae2390eae\"\\n\\t\\thash2 = \"1e67476281c1ec1cf40e17d7fc28a3ab3250b474ef41cb10a72130990f0be6a0\"\\n\\t\\thash3 = \"49e7bac7e0db87bf3f0185e9cf51f2539dbc11384fefced465230c4e5bce0872\"\\n\\tstrings:\\n\\t\\t$s1 = \"%3u - Directory \\'%s\\' (*.kirbi)\" fullword wide\\n\\t\\t$s2 = \"%*s  pPublicKey         : \" fullword wide\\n\\t\\t$s3 = \"ad_hoc_network_formed\" fullword wide\\n\\t\\t$s4 = \"<3 eo.oe ~ ANSSI E>\" fullword wide\\n\\t\\t$s5 = \"\\\\\\\\*.kirbi\" fullword wide\\n\\n\\t\\t$c1 = \"kuhl_m_lsadump_getUsersAndSamKey ; kull_m_registry_RegOpenKeyEx SAM Accounts (0x%08x)\" fullword wide\\n\\t\\t$c2 = \"kuhl_m_lsadump_getComputerAndSyskey ; kuhl_m_lsadump_getSyskey KO\" fullword wide\\n\\tcondition:\\n\\t\\t( uint16(0) == 0x5a4d and filesize < 1000KB and 1 of them ) or 2 of them\\n}': '```\\nRule Name\\n  Powerkatz_DLL_Generic\\n\\nDescription\\n  This YARA rule is crafted to detect Powerkatz—a variant of the credential-stealing tool Mimikatz, specifically adapted to operate within memory via PowerShell scripts. This rule may overlap with other detections for various Mimikatz versions.\\n\\nReference\\n  PowerKatz Analysis\\n\\nIndicators / String Matches\\n  This rule matches the following wide (Unicode) strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $s1\\t\"%3u - Directory \\'%s\\' (*.kirbi)\"\\tIndicates location of Kerberos ticket files\\n  $s2\\t\"%*s  pPublicKey         : \"\\tRelated to cryptographic operations\\n  $s3\\t\"ad_hoc_network_formed\"\\tPossibly related to network operations\\n  $s4\\t\"<3 eo.oe ~ ANSSI E>\"\\tPotential marker or signature string\\n  $s5\\t\"\\\\\\\\*.kirbi\"\\tTargets Kerberos ticket files\\n\\n  Control Pattern ID\\tPattern\\tNotes\\n  $c1\\t\"kuhl_m_lsadump_getUsersAndSamKey ; kull_m_registry_RegOpenKeyEx SAM Accounts (0x%08x)\"\\tFunction to dump user and SAM keys\\n  $c2\\t\"kuhl_m_lsadump_getComputerAndSyskey ; kuhl_m_lsadump_getSyskey KO\"\\tFunction for obtaining system keys\\n\\n  All string patterns use fullword and wide modifiers, meaning they match exact full Unicode words.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  - The file has a valid DOS MZ header (uint16(0) == 0x5A4D) and the file size is less than 1000KB, and at least one of the specified string patterns ($s1 through $c2) is found.\\n\\n  OR\\n\\n  - At least two of the specified string patterns ($s1 through $c2) are found, regardless of file size or header check.\\n\\nKnown File Hashes\\n  SHA256: c20f30326fcebad25446cf2e267c341ac34664efad5c50ff07f0738ae2390eae\\n  SHA256: 1e67476281c1ec1cf40e17d7fc28a3ab3250b474ef41cb10a72130990f0be6a0\\n  SHA256: 49e7bac7e0db87bf3f0185e9cf51f2539dbc11384fefced465230c4e5bce0872\\n```\\n',\n",
              " 'rule RomeoCharlie\\n{\\n\\tmeta:\\n\\t\\tcopyright = \"2015 Novetta Solutions\"\\n\\t\\tauthor = \"Novetta Threat Research & Interdiction Group - trig@novetta.com\"\\n\\t\\tSource = \"a82108ef7115931b3fbe1fab99448c4139e22feda27c1b1d29325710671154e8\"\\n\\n\\tstrings:\\n\\t\\t$auth1 = \"Success - Accept Auth\"\\n\\t\\t$auth2 = \"Fail - Accept Auth\"\\n\\n\\t/*\\n\\t\\t81 E3 FF FF 00 00  and     ebx, 0FFFFh\\n\\t\\t8B EB              mov     ebp, ebx\\n\\t\\t57                 push    edi\\n\\t\\tC1 EE 10           shr     esi, 10h\\n\\t\\t81 E5 FF FF 00 00  and     ebp, 0FFFFh\\n\\t\\t8B FE              mov     edi, esi\\n\\t\\t8B C5              mov     eax, ebp\\n\\t\\t81 E7 FF FF 00 00  and     edi, 0FFFFh\\n\\t\\tC1 E0 10           shl     eax, 10h\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\t0B C7              or      eax, edi\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\t50                 push    eax             ; _DWORD\\n\\t\\t68 10 14 11 71     push    offset sub_71111410; _DWORD\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\tFF 15 5C 8E 12 71  call    CreateThread_0\\n\\t\\tC1 E7 10           shl     edi, 10h\\n\\t*/\\n\\n\\t$startupRelayThreads = {81 ?? FF FF 00 00 8B ?? 5? C1 ?? 10 81 ?? FF FF 00 00 8B ?? 8B ?? 81 ?? FF FF 00 00 C1 ?? 10 6A 00 0B ?? 6A 00 \\t50 68 [4] 6A 00 6A 00 FF 15 [4] C1 ?? 10 }\\n\\n\\t/*\\n\\tsource: 641808833ad34f2e5143001c8147d779dbfd2a80a80ce0cfc81474d422882adb\\n\\t\\t25 00 20 00 00     and     eax, 2000h\\n\\t\\t3D 00 20 00 00     cmp     eax, 2000h\\n\\t\\t0F 94 C1           setz    cl\\n\\t\\t81 E2 80 00 00 00  and     edx, 80h\\n\\t\\t33 C0              xor     eax, eax\\n\\t\\t80 FA 80           cmp     dl, 80h\\n\\t\\t0F 94 C0           setz    al\\n\\t\\t03 C8              add     ecx, eax\\n\\t\\t33 D2              xor     edx, edx\\n\\t\\t83 F9 01           cmp     ecx, 1\\n\\t*/\\n\\n\\t$crypto = {2? 00 20 00 00 3? 00 20 00 00 0F [2] 81 ?? 80 00 00 00 33 ?? 80 ?? 80 0F [2] 03 ?? 33 ?? 83 ?? 01 }\\n\\n\\tcondition:\\n\\t\\tall of ($auth*) \\n\\t\\tor $startupRelayThreads in ((pe.sections[pe.section_index(\".text\")].raw_data_offset)..(pe.sections[pe.section_index(\".text\")].raw_data_offset + pe.sections[pe.section_index(\".text\")].raw_data_size))\\n\\t\\tor $crypto in ((pe.sections[pe.section_index(\".text\")].raw_data_offset)..(pe.sections[pe.section_index(\".text\")].raw_data_offset + pe.sections[pe.section_index(\".text\")].raw_data_size))\\n}': 'Rule Name  \\n  RomeoCharlie\\n\\nDescription  \\n  This YARA rule detects specific patterns associated with certain malware samples analyzed by Novetta. The rule includes string matches that indicate authentication success or failure, as well as patterns for a known technique involving initiation of relay threads and cryptographic operations within a PE file\\'s .text section. This rule helps identify these techniques by matching either of the string patterns or the known byte patterns within .text sections commonly used in malicious binaries.\\n\\nReference  \\n  There is no direct public reference provided for this YARA rule, but it is attributed to Novetta\\'s Threat Research & Interdiction Group.\\n\\nIndicators / String Matches  \\n  The rule matches the following string and byte patterns:\\n\\n  String ID | Pattern                  | Notes  \\n  $auth1    | \"Success - Accept Auth\"  | Indicates successful authentication  \\n  $auth2    | \"Fail - Accept Auth\"     | Indicates authentication failure  \\n\\n  Byte Pattern ID | Pattern Description  \\n  $startupRelayThreads | Matches specific byte pattern for starting relay threads, typical of malware operations.  \\n  $crypto             | Matches specific byte pattern associated with certain cryptographic operations found in malware.\\n\\nCondition Logic  \\n  The rule triggers if any of the following conditions are met:\\n\\n  - Either of the authentication strings ($auth1 or $auth2) are present.\\n  - The $startupRelayThreads byte pattern is found within the .text section of the PE file.\\n  - The $crypto byte pattern is found within the .text section of the PE file.\\n\\nKnown File Hash  \\n  The rule was derived using a known sample hash:  \\n  SHA256: a82108ef7115931b3fbe1fab99448c4139e22feda27c1b1d29325710671154e8',\n",
              " 'rule TreasureHunt\\n  {\\n    meta:\\n      author = \"Minerva Labs\"\\n      ref =\"http://www.minerva-labs.com/#!Cybercriminals-Adopt-the-Mossad-Emblem/c7a5/573da2d60cf2f90ca6f6e3ed\"\\n      date = \"2016/06\"\\n      maltype = \"Point of Sale (POS) Malware\"\\n      filetype = \"exe\"\\n\\n    strings:\\n      $a = \"treasureHunter.pdb\"\\n      $b = \"jucheck\"\\n      $c = \"cmdLineDecrypted\"\\n\\n    condition:\\n      all of them\\n}': '```\\nRule Name\\n  TreasureHunt\\n\\nDescription\\n  This YARA rule aims to identify a specific Point of Sale (POS) malware referred to as \"TreasureHunt.\" It detects executables containing specific strings that suggest malware functionality related to command-line decryption and possibly masquerading as a legitimate Java update checker (jucheck). The inclusion of a PDB path string indicates potential association with debugging or development contexts.\\n\\nReference\\n  Minerva Labs Report\\n  Full Report: http://www.minerva-labs.com/#!Cybercriminals-Adopt-the-Mossad-Emblem/c7a5/573da2d60cf2f90ca6f6e3ed\\n\\nIndicators / String Matches\\n  This rule matches the following strings:\\n\\n  String ID\\tPattern\\t                      Notes\\n  $a\\t\"treasureHunter.pdb\"\\t      PDB file path, possibly for debugging\\n  $b\\t\"jucheck\"\\t                  Potential impersonation of Java update checker\\n  $c\\t\"cmdLineDecrypted\"\\t          Functionality related to command-line decryption\\n\\n  All string patterns are considered essential for detection.\\n\\nCondition Logic\\n  The rule triggers if all of the specified string patterns ($a, $b, and $c) are found within the file, indicating the presence of the TreasureHunt malware.\\n\\n```',\n",
              " 'rule HKTL_NET_GUID_CSharpSetThreadContext {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/djhohnstein/CSharpSetThreadContext\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"a1e28c8c-b3bd-44de-85b9-8aa7c18a714d\" ascii nocase wide\\n        $typelibguid1 = \"87c5970e-0c77-4182-afe2-3fe96f785ebb\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '```\\nRule Name\\n  HKTL_NET_GUID_CSharpSetThreadContext\\n\\nDescription\\n  This YARA rule is designed to detect C# red/black-team tools by identifying specific type library GUIDs associated with the CSharpSetThreadContext repository. The rule targets tools that may use these typelib GUIDs for malicious or penetration testing purposes.\\n\\nReference\\n  CSharpSetThreadContext Repository\\n  Full Repository: https://github.com/djhohnstein/CSharpSetThreadContext\\n\\nIndicators / String Matches\\n  This rule matches the following wide (Unicode) strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $typelibguid0\\t\"a1e28c8c-b3bd-44de-85b9-8aa7c18a714d\"\\tType library GUID used in CSharpSetThreadContext\\n  $typelibguid1\\t\"87c5970e-0c77-4182-afe2-3fe96f785ebb\"\\tAnother type library GUID used in CSharpSetThreadContext\\n\\n  Both string patterns use ascii, nocase, and wide modifiers, meaning they match ASCII as well as Unicode strings in a case-insensitive manner.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  The file has a valid DOS MZ header (uint16(0) == 0x5A4D).\\n\\n  The file also has a valid PE header signature (uint32(uint32(0x3C)) == 0x00004550).\\n\\n  Any of the specified string patterns ($typelibguid0 or $typelibguid1) are found.\\n```\\n',\n",
              " 'rule HKTL_NET_GUID_DLL_Injection {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/ihack4falafel/DLL-Injection\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"3d7e1433-f81a-428a-934f-7cc7fcf1149d\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '    Rule Name\\n      HKTL_NET_GUID_DLL_Injection\\n\\n    Description\\n      This YARA rule is designed to detect C# injection tools used by red and black team operations by identifying a specific typelib GUID. The rule targets tools that manipulate or inject themselves into processes using a specific typelib GUID, potentially indicating malicious activities associated with DLL injection techniques.\\n\\n    Reference\\n      GitHub - DLL Injection \\n      Full Reference: https://github.com/ihack4falafel/DLL-Injection\\n\\n    Indicators / String Matches\\n      This rule matches the following strings with specific properties:\\n\\n      String ID\\tPattern\\tNotes\\n      $typelibguid0\\t\"3d7e1433-f81a-428a-934f-7cc7fcf1149d\"\\tTypelib GUID related to DLL injection\\n\\n      The pattern uses ascii, nocase, and wide modifiers, allowing for flexible detection of the GUID in different encodings and cases.\\n\\n    Condition Logic\\n      The rule triggers if:\\n\\n      The file starts with a valid DOS MZ header (uint16(0) == 0x5A4D).\\n      \\n      The file has a valid PE header located at the offset specified in the DOS header (uint32(uint32(0x3C)) == 0x00004550).\\n\\n      Any of the specified string patterns ($typelibguid0) are found.',\n",
              " 'rule HKTL_NET_GUID_LimeUSB_Csharp {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/NYAN-x-CAT/LimeUSB-Csharp\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"94ea43ab-7878-4048-a64e-2b21b3b4366d\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '    Rule Name\\n      HKTL_NET_GUID_LimeUSB_Csharp\\n\\n    Description\\n      This YARA rule is designed to identify C# tools often associated with red team or black hat operations, specifically through the detection of a Type Library GUID string within binaries. The rule targets deployments or tools similar to those found in the LimeUSB-Csharp repository, suggesting potential misuse for unauthorized purposes.\\n\\n    Reference\\n      LimeUSB-Csharp\\n      Full Reference: https://github.com/NYAN-x-CAT/LimeUSB-Csharp\\n\\n    Indicators / String Matches\\n      This rule matches the following strings:\\n\\n      String ID \\tPattern\\tNotes\\n      $typelibguid0\\t\"94ea43ab-7878-4048-a64e-2b21b3b4366d\"\\tType Library GUID associated with C# tools\\n\\n      The match is case-insensitive and supports both ASCII and wide (Unicode) formats.\\n\\n    Condition Logic\\n      The rule triggers if:\\n\\n      The file contains a valid DOS MZ header (uint16(0) == 0x5A4D).\\n\\n      The file contains a valid PE header signature (uint32(uint32(0x3C)) == 0x00004550).\\n\\n      Any of the specified string patterns are found.',\n",
              " 'rule HKTL_NET_GUID_Ladon {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/k8gege/Ladon\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"c335405f-5df2-4c7d-9b53-d65adfbed412\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '```plaintext\\nRule Name\\n  HKTL_NET_GUID_Ladon\\n\\nDescription\\n  This YARA rule is designed to detect the presence of specific C# red/black-team tools via their typelib GUID. It identifies potentially malicious tools used for post-exploitation activities by analyzing the typelib GUID embedded within executables. The presence of these tools may indicate unauthorized activities related to red teaming or black hat operations.\\n\\nReference\\n  Ladon Tool Repository\\n  Source: https://github.com/k8gege/Ladon\\n\\nIndicators / String Matches\\n  This rule matches the following strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $typelibguid0\\t\"c335405f-5df2-4c7d-9b53-d65adfbed412\"\\tTypelib GUID used in C# tools\\n\\n  The string patterns are checked with ascii, nocase, and wide modifiers, allowing for flexible matching of typelibs.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  The file has a valid MZ header (uint16(0) == 0x5A4D).\\n  \\n  The file has a valid PE header signature (uint32(uint32(0x3C)) == 0x00004550).\\n\\n  Any of the specified string patterns ($typelibguid0) are found.\\n```'}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yara_cti_sample_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7fce448a",
      "metadata": {},
      "outputs": [],
      "source": [
        "yaras, ctis = zip(*yara_cti_sample_dict.items())\n",
        "yaras = list(yaras)\n",
        "ctis = list(ctis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "6685b99a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(yaras), len(ctis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c463e143",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_cti_yara_data_to_training_data(data: list[dict]) -> list[tuple]:\n",
        "    \"\"\"\n",
        "    Format the CTI YARA data into training data.\n",
        "\n",
        "    :param data: The data to format\n",
        "    :return: Formatted training data\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    for dataset in data:\n",
        "        for key, value in dataset.items():\n",
        "            training_data.append((key, value))\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6515bc74",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9175\n"
          ]
        }
      ],
      "source": [
        "# Sample Dataset Format (list of (anchor, positive) sentence pairs)\n",
        "full_dataset = format_cti_yara_data_to_training_data([loaded_v1_data, loaded_v2_data])\n",
        "print(len(full_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "49e19105",
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_10_test_samples(training_data: list[tuple], test_pairs: dict) -> list[tuple]:\n",
        "    # Extract all test keys and values into sets for quick lookup\n",
        "    test_keys = set(test_pairs.keys())\n",
        "    test_values = set(test_pairs.values())\n",
        "    \n",
        "    # Filter training data\n",
        "    filtered_data = [(key, value) for key, value in training_data if key not in test_keys and value not in test_values]\n",
        "    \n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b7101f66",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9155\n"
          ]
        }
      ],
      "source": [
        "# Sample Dataset Format (list of (anchor, positive) sentence pairs)\n",
        "full_dataset = remove_10_test_samples(full_dataset, yara_cti_sample_dict)\n",
        "print(len(full_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bfc58e48",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into training and testing sets (80% train, 20% test)\n",
        "train_pairs, test_pairs = train_test_split(full_dataset, test_size=0.1, random_state=SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7f031995",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "916"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_pairs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54d3c188",
      "metadata": {},
      "source": [
        "# Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f0eb4848",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Dataset\n",
        "class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor, positive = self.data[idx]\n",
        "        encoded = self.tokenizer([anchor, positive], padding=\"max_length\", truncation=True,\n",
        "                                 max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids_a\": encoded[\"input_ids\"][0],\n",
        "            \"attention_mask_a\": encoded[\"attention_mask\"][0],\n",
        "            \"input_ids_b\": encoded[\"input_ids\"][1],\n",
        "            \"attention_mask_b\": encoded[\"attention_mask\"][1],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a8eaa4aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bi-Encoder Model\n",
        "class SentenceEncoder(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
        "        return nn.functional.normalize(embeddings, p=2, dim=1)  # Normalize for cosine similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c2f9ad1",
      "metadata": {},
      "source": [
        "# Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "e4ed2807",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_rule_from_cti_prompt(input_cti: str) -> str:\n",
        "\n",
        "  rule_generation_prompt = f\"\"\"\n",
        "\n",
        "    You are a cybersecurity expert tasked with performing YARA rule generation for a given Cyber Threat Intelligence (CTI).\n",
        "    There is a sample task input and output provided below.\n",
        "    \n",
        "    Sample CTI Input and corresponding YARA Output:\n",
        "\n",
        "    CTI Input:\n",
        "        \n",
        "      Rule Name\n",
        "        APT30_Sample_2\n",
        "\n",
        "      Description\n",
        "        This YARA rule is designed to detect a specific malware sample associated with the APT30 threat group, as documented in a report by FireEye. The binary appears to be masquerading as a legitimate Microsoft Word-related executable, with embedded strings referencing ForZRLnkWordDlg.EXE, suggesting impersonation of Microsoft Office components.\n",
        "\n",
        "      Reference\n",
        "        FireEye APT30 Report\n",
        "        Full Report: https://www2.fireeye.com/rs/fireye/images/rpt-apt30.pdf\n",
        "\n",
        "      Indicators / String Matches\n",
        "        This rule matches the following wide (Unicode) strings:\n",
        "\n",
        "        String ID\tPattern\tNotes\n",
        "        $s0\t\"ForZRLnkWordDlg.EXE\"\tExecutable filename\n",
        "        $s1\t\"ForZRLnkWordDlg Microsoft \"\tVendor impersonation\n",
        "        $s9\t\"ForZRLnkWordDlg 1.0 \"\tFake version info\n",
        "        $s11\t\"ForZRLnkWordDlg\"\tGeneric name\n",
        "        $s12\t\" (C) 2011\"\tFake copyright year\n",
        "        \n",
        "        All string patterns use fullword and wide modifiers, meaning they match exact full Unicode words.\n",
        "\n",
        "      Condition Logic\n",
        "        The rule triggers if:\n",
        "\n",
        "        The file size is less than 100KB.\n",
        "\n",
        "        The file has a valid DOS MZ header (uint16(0) == 0x5A4D).\n",
        "\n",
        "        All of the specified string patterns ($s0 through $s12) are found.\n",
        "\n",
        "      Known File Hash\n",
        "        SHA1: 0359ffbef6a752ee1a54447b26e272f4a5a35167\n",
        "\n",
        "      Rule UUID\n",
        "        821a2de9-48c4-58d8-acc4-1e25025ab5cf\n",
        "\n",
        "      \n",
        "    YARA Output:\n",
        "        \n",
        "      rule APT30_Sample_2 {{\n",
        "        meta:\n",
        "          description = \"FireEye APT30 Report Sample\"\n",
        "          license = \"Detection Rule License 1.1 https://github.com/Neo23x0/signature-base/blob/master/LICENSE\"\n",
        "          author = \"Florian Roth (Nextron Systems)\"\n",
        "          reference = \"https://www2.fireeye.com/rs/fireye/images/rpt-apt30.pdf\"\n",
        "          date = \"2015/04/13\"\n",
        "          hash = \"0359ffbef6a752ee1a54447b26e272f4a5a35167\"\n",
        "          id = \"821a2de9-48c4-58d8-acc4-1e25025ab5cf\"\n",
        "        strings:\n",
        "          $s0 = \"ForZRLnkWordDlg.EXE\" fullword wide\n",
        "          $s1 = \"ForZRLnkWordDlg Microsoft \" fullword wide\n",
        "          $s9 = \"ForZRLnkWordDlg 1.0 \" fullword wide\n",
        "          $s11 = \"ForZRLnkWordDlg\" fullword wide\n",
        "          $s12 = \" (C) 2011\" fullword wide\n",
        "        condition:\n",
        "          filesize < 100KB and uint16(0) == 0x5A4D and all of them\n",
        "      }}\n",
        "\n",
        "\n",
        "    Generate YARA from the provided CTI. Do not include anything that is not provided.\n",
        "    Do not print anything like sure here is the CTI or anything else. Only print the CTI. \n",
        "\n",
        "    CTI Input: \n",
        "    \n",
        "      {input_cti}\n",
        "\n",
        "    YARA Output:\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  return rule_generation_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "555fdb3d",
      "metadata": {},
      "source": [
        "# Test Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "8778fc66",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ctis = [i[1] for i in test_pairs]\n",
        "gt_rules = [i[0] for i in test_pairs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "a05e6431",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(916, 916)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_ctis), len(gt_rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "07c6da51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "    You are a cybersecurity expert tasked with performing YARA rule generation for a given Cyber Threat Intelligence (CTI).\n",
            "    There is a sample task input and output provided below.\n",
            "    \n",
            "    Sample CTI Input and corresponding YARA Output:\n",
            "\n",
            "    CTI Input:\n",
            "        \n",
            "      Rule Name\n",
            "        APT30_Sample_2\n",
            "\n",
            "      Description\n",
            "        This YARA rule is designed to detect a specific malware sample associated with the APT30 threat group, as documented in a report by FireEye. The binary appears to be masquerading as a legitimate Microsoft Word-related executable, with embedded strings referencing ForZRLnkWordDlg.EXE, suggesting impersonation of Microsoft Office components.\n",
            "\n",
            "      Reference\n",
            "        FireEye APT30 Report\n",
            "        Full Report: https://www2.fireeye.com/rs/fireye/images/rpt-apt30.pdf\n",
            "\n",
            "      Indicators / String Matches\n",
            "        This rule matches the following wide (Unicode) strings:\n",
            "\n",
            "        String ID\tPattern\tNotes\n",
            "        $s0\t\"ForZRLnkWordDlg.EXE\"\tExecutable filename\n",
            "        $s1\t\"ForZRLnkWordDlg Microsoft \"\tVendor impersonation\n",
            "        $s9\t\"ForZRLnkWordDlg 1.0 \"\tFake version info\n",
            "        $s11\t\"ForZRLnkWordDlg\"\tGeneric name\n",
            "        $s12\t\" (C) 2011\"\tFake copyright year\n",
            "        \n",
            "        All string patterns use fullword and wide modifiers, meaning they match exact full Unicode words.\n",
            "\n",
            "      Condition Logic\n",
            "        The rule triggers if:\n",
            "\n",
            "        The file size is less than 100KB.\n",
            "\n",
            "        The file has a valid DOS MZ header (uint16(0) == 0x5A4D).\n",
            "\n",
            "        All of the specified string patterns ($s0 through $s12) are found.\n",
            "\n",
            "      Known File Hash\n",
            "        SHA1: 0359ffbef6a752ee1a54447b26e272f4a5a35167\n",
            "\n",
            "      Rule UUID\n",
            "        821a2de9-48c4-58d8-acc4-1e25025ab5cf\n",
            "\n",
            "      \n",
            "    YARA Output:\n",
            "        \n",
            "      rule APT30_Sample_2 {\n",
            "        meta:\n",
            "          description = \"FireEye APT30 Report Sample\"\n",
            "          license = \"Detection Rule License 1.1 https://github.com/Neo23x0/signature-base/blob/master/LICENSE\"\n",
            "          author = \"Florian Roth (Nextron Systems)\"\n",
            "          reference = \"https://www2.fireeye.com/rs/fireye/images/rpt-apt30.pdf\"\n",
            "          date = \"2015/04/13\"\n",
            "          hash = \"0359ffbef6a752ee1a54447b26e272f4a5a35167\"\n",
            "          id = \"821a2de9-48c4-58d8-acc4-1e25025ab5cf\"\n",
            "        strings:\n",
            "          $s0 = \"ForZRLnkWordDlg.EXE\" fullword wide\n",
            "          $s1 = \"ForZRLnkWordDlg Microsoft \" fullword wide\n",
            "          $s9 = \"ForZRLnkWordDlg 1.0 \" fullword wide\n",
            "          $s11 = \"ForZRLnkWordDlg\" fullword wide\n",
            "          $s12 = \" (C) 2011\" fullword wide\n",
            "        condition:\n",
            "          filesize < 100KB and uint16(0) == 0x5A4D and all of them\n",
            "      }\n",
            "\n",
            "\n",
            "    Generate YARA from the provided CTI. Do not include anything that is not provided.\n",
            "    Do not print anything like sure here is the CTI or anything else. Only print the CTI. \n",
            "\n",
            "    CTI Input: \n",
            "    \n",
            "      ```\n",
            "Rule Name\n",
            "  FSO_s_remview_2\n",
            "\n",
            "Description\n",
            "  This YARA rule is designed to detect a specific webshell file named \"remview.php\". It targets malicious PHP code patterns typically used in webshells to execute arbitrary commands, often found on compromised web servers.\n",
            "\n",
            "Indicators / String Matches\n",
            "  This rule matches the following strings:\n",
            "\n",
            "  String ID\tPattern\tNotes\n",
            "  $s0\t\"<xmp>$out</\"\tHTML tag pattern used for output display\n",
            "  $s1\t\".mm(\\\"Eval PHP code\\\").\"\tPHP code execution function pattern\n",
            "\n",
            "  All string patterns must be present for the rule to trigger.\n",
            "\n",
            "Condition Logic\n",
            "  The rule triggers if all the specified string patterns ($s0 and $s1) are found in a file.\n",
            "\n",
            "Known File Hash\n",
            "  SHA1: b4a09911a5b23e00b55abe546ded691c\n",
            "```\n",
            "\n",
            "    YARA Output:\n",
            "\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "prompt = generate_rule_from_cti_prompt(test_ctis[0])\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "4424b728",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```yara\n",
            "rule FSO_s_remview_2 {\n",
            "  meta:\n",
            "    description = \"Detection of specific webshell file 'remview.php' targeting malicious PHP code patterns.\"\n",
            "    hash = \"b4a09911a5b23e00b55abe546ded691c\"\n",
            "  strings:\n",
            "    $s0 = \"<xmp>$out</\"\n",
            "    $s1 = \".mm(\\\"Eval PHP code\\\").\"\n",
            "  condition:\n",
            "    all of them\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "test_rule = get_open_ai_response(prompt)\n",
        "print(test_rule)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc930ed7",
      "metadata": {},
      "source": [
        "# Generate Rule from CTI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1ae0261e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating YARA rules from CTIs...: 100%|██████████| 916/916 [42:44<00:00,  2.80s/it]  \n"
          ]
        }
      ],
      "source": [
        "generated_rules = []\n",
        "\n",
        "inference_counter = 0\n",
        "for cti in tqdm(test_ctis, \"Generating YARA rules from CTIs...\"):\n",
        "  prompt = generate_rule_from_cti_prompt(cti)\n",
        "  rule = get_open_ai_response(prompt)\n",
        "  generated_rules.append(rule)\n",
        "  file_name = f\"quantitative_eval_yara_rule_{inference_counter}.txt\"\n",
        "  save_string_as_txt(generated_rule_dir_path, file_name, rule)\n",
        "  inference_counter += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c9464a3f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "916"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(generated_rules)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d3e124",
      "metadata": {},
      "source": [
        "# CTI-Rule Semantic Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8301c101",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_dot_product_matrix_batched(model, tokenizer, test_yaras, test_ctis, batch_size=64):\n",
        "    # Tokenize yaras once (since all CTIs will be compared to them)\n",
        "    tokenized_yaras = tokenizer(test_yaras, return_tensors=\"pt\", padding=True, max_length=MAX_LEN, truncation=True)\n",
        "    input_ids_yaras = tokenized_yaras[\"input_ids\"].to(DEVICE)\n",
        "    attention_mask_yaras = tokenized_yaras[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        emb_yaras = model(input_ids_yaras, attention_mask_yaras)  # (802, dim)\n",
        "        emb_yaras = emb_yaras.detach()\n",
        "\n",
        "    # Prepare output tensor for all dot products\n",
        "    num_ctis = len(test_ctis)\n",
        "    dot_product_matrix = []\n",
        "\n",
        "    for i in range(0, num_ctis, batch_size):\n",
        "        batch_ctis = test_ctis[i:i + batch_size]\n",
        "        tokenized_ctis = tokenizer(batch_ctis, return_tensors=\"pt\", padding=True, max_length=MAX_LEN, truncation=True)\n",
        "        input_ids_ctis = tokenized_ctis[\"input_ids\"].to(DEVICE)\n",
        "        attention_mask_ctis = tokenized_ctis[\"attention_mask\"].to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            emb_ctis = model(input_ids_ctis, attention_mask_ctis)  # (B, dim)\n",
        "            dot_product_batch = torch.matmul(emb_ctis, emb_yaras.T)  # (B, 802)\n",
        "            dot_product_matrix.append(dot_product_batch.cpu())\n",
        "\n",
        "        # Cleanup\n",
        "        del input_ids_ctis, attention_mask_ctis, emb_ctis, dot_product_batch\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Concatenate batches into full matrix\n",
        "    dot_product_matrix = torch.cat(dot_product_matrix, dim=0)  # (802, 802)\n",
        "    return dot_product_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "0eb0a160",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RUN = 1\n",
        "FINE_TUNED_MODEL_NAME = \"all-mpnet-base-v2\"\n",
        "MODEL_NAME = f\"/data/common/models/sentence-transformers/{FINE_TUNED_MODEL_NAME}\"\n",
        "FINE_TUNED_MODEL_STATE_NAME = f\"contrastive_encoder_r{RUN}.pt\"\n",
        "MODEL_SAVE_PATH = os.path.join(project_base_path, f\"script/fine_tuning/bi-encoder/snort/{FINE_TUNED_MODEL_NAME}/{FINE_TUNED_MODEL_STATE_NAME}\")\n",
        "\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load model\n",
        "model = SentenceEncoder(MODEL_NAME).to(DEVICE)\n",
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c59eddaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "dot_product_matrix_test = compute_dot_product_matrix_batched(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_yaras=generated_rules,\n",
        "    test_ctis=gt_rules,\n",
        "    batch_size=256\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "4513ca29",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def extract_sigmoid_diagonal(dot_product_matrix: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Extracts principal diagonal from a dot-product matrix,\n",
        "    applies sigmoid to each value, and returns the sigmoid list.\n",
        "    Also prints the mean of sigmoid values.\n",
        "\n",
        "    Args:\n",
        "        dot_product_matrix (torch.Tensor): A square matrix of shape [N x N]\n",
        "\n",
        "    Returns:\n",
        "        List[float]: Sigmoid values of diagonal entries\n",
        "    \"\"\"\n",
        "    assert dot_product_matrix.shape[0] == dot_product_matrix.shape[1], \"Matrix must be square.\"\n",
        "\n",
        "    # Step 1: Extract diagonal\n",
        "    diag_values = dot_product_matrix.diag()  # shape: (N,)\n",
        "\n",
        "    # Step 2: Apply sigmoid\n",
        "    sigmoid_values = torch.sigmoid(diag_values)\n",
        "\n",
        "    # Step 3: Convert to list and compute mean\n",
        "    sigmoid_list = sigmoid_values.tolist()\n",
        "    mean_value = torch.mean(sigmoid_values).item()\n",
        "\n",
        "    # Output\n",
        "    print(f\"Mean of sigmoid(diagonal values): {mean_value:.4f}\")\n",
        "    return sigmoid_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "d2848fab",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of sigmoid(diagonal values): 0.6710\n"
          ]
        }
      ],
      "source": [
        "sigmoid_diagonal_scores = extract_sigmoid_diagonal(dot_product_matrix_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2277be88",
      "metadata": {},
      "source": [
        "# Ragas "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8151fac9",
      "metadata": {},
      "outputs": [],
      "source": [
        "open_ai_key = \"OPENAI_KEY\"\n",
        "os.environ['OPENAI_API_KEY'] = open_ai_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "608a9f16",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "def compute_dot_product_matrix_openai(test_yaras, test_ctis, batch_size=50):\n",
        "    embedder = OpenAIEmbeddings()  # Uses text-embedding-ada-002 by default\n",
        "\n",
        "    # Step 1: Get embeddings for all yara rules\n",
        "    yara_embeddings = []\n",
        "    for i in range(0, len(test_yaras), batch_size):\n",
        "        batch = test_yaras[i:i + batch_size]\n",
        "        yara_embeddings.extend(embedder.embed_documents(batch))  # List of vectors\n",
        "\n",
        "    yara_embeddings = np.array(yara_embeddings)  # Shape: (N, D)\n",
        "    yara_embeddings_norm = np.linalg.norm(yara_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Step 2: Compute batched dot products with CTIs\n",
        "    dot_product_matrix = []\n",
        "\n",
        "    for i in range(0, len(test_ctis), batch_size):\n",
        "        batch = test_ctis[i:i + batch_size]\n",
        "        cti_embeddings = embedder.embed_documents(batch)\n",
        "        cti_embeddings = np.array(cti_embeddings)\n",
        "        cti_embeddings_norm = np.linalg.norm(cti_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "        # Normalize and compute dot product\n",
        "        sim_matrix = np.dot(cti_embeddings, yara_embeddings.T) / (\n",
        "            cti_embeddings_norm @ yara_embeddings_norm.T\n",
        "        )\n",
        "        dot_product_matrix.append(sim_matrix)\n",
        "\n",
        "    dot_product_matrix = np.vstack(dot_product_matrix)  # Final shape: (len(test_ctis), len(test_yaras))\n",
        "    return dot_product_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "bd279941",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_diagonal(dot_product_matrix: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Extracts principal diagonal from a dot-product matrix,\n",
        "    applies sigmoid to each value, and returns the sigmoid list.\n",
        "    Also prints the mean of sigmoid values.\n",
        "\n",
        "    Args:\n",
        "        dot_product_matrix (torch.Tensor): A square matrix of shape [N x N]\n",
        "\n",
        "    Returns:\n",
        "        List[float]: Sigmoid values of diagonal entries\n",
        "    \"\"\"\n",
        "    assert dot_product_matrix.shape[0] == dot_product_matrix.shape[1], \"Matrix must be square.\"\n",
        "\n",
        "    # Step 1: Extract diagonal\n",
        "    diag_values = dot_product_matrix.diag()  # shape: (N,)\n",
        "\n",
        "    # Step 3: Convert to list and compute mean\n",
        "    diag_list = diag_values.tolist()\n",
        "    mean_value = torch.mean(diag_values).item()\n",
        "\n",
        "    # Output\n",
        "    print(f\"Mean of sigmoid(diagonal values): {mean_value:.4f}\")\n",
        "    return diag_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e68f7d6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3441400/711577257.py:5: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embedder = OpenAIEmbeddings()  # Uses text-embedding-ada-002 by default\n"
          ]
        }
      ],
      "source": [
        "dot_product_matrix_test = compute_dot_product_matrix_openai(\n",
        "    test_yaras=generated_rules,\n",
        "    test_ctis=gt_rules,\n",
        "    batch_size=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "6ef5d038",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of sigmoid(diagonal values): 0.9196\n"
          ]
        }
      ],
      "source": [
        "diagonal_scores_openai = extract_diagonal(torch.tensor(dot_product_matrix_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a7dd731",
      "metadata": {},
      "source": [
        "# Bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "11d79b1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from bert_score import score\n",
        "\n",
        "def compute_bert_scores(cti_list, generated_rules, lang=\"en\", model_type=\"bert-base-uncased\"):\n",
        "    \"\"\"\n",
        "    Computes BERTScore between CTI descriptions and generated YARA rules.\n",
        "\n",
        "    Args:\n",
        "        cti_list (List[str]): List of CTI strings.\n",
        "        generated_rules (List[str]): Corresponding generated YARA rule strings.\n",
        "        lang (str): Language (default = \"en\").\n",
        "        model_type (str): BERT model to use (default = DeBERTa-MNLI).\n",
        "\n",
        "    Returns:\n",
        "        dict: Precision, Recall, F1 scores (averaged) and all individual F1s.\n",
        "    \"\"\"\n",
        "    assert len(cti_list) == len(generated_rules), \"Mismatch in CTI and rule count.\"\n",
        "\n",
        "    P, R, F1 = score(generated_rules, cti_list, lang=lang, model_type=model_type, verbose=True)\n",
        "\n",
        "    mean_p = P.mean().item()\n",
        "    mean_r = R.mean().item()\n",
        "    mean_f1 = F1.mean().item()\n",
        "\n",
        "    print(f\"\\nBERTScore Results:\\nPrecision: {mean_p:.4f} | Recall: {mean_r:.4f} | F1: {mean_f1:.4f}\")\n",
        "    return {\n",
        "        \"precision\": mean_p,\n",
        "        \"recall\": mean_r,\n",
        "        \"f1\": mean_f1,\n",
        "        \"f1_scores\": F1.tolist()  # optional: return individual F1s\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "61009063",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "calculating scores...\n",
            "computing bert embedding.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7574e93ffa8544c793e216e9fed8bbea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "computing greedy matching.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9f46279075b4ba385b26bbfd8b306c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done in 7.43 seconds, 123.25 sentences/sec\n",
            "\n",
            "BERTScore Results:\n",
            "Precision: 0.8329 | Recall: 0.8741 | F1: 0.8514\n"
          ]
        }
      ],
      "source": [
        "bert_score_results = compute_bert_scores(gt_rules, generated_rules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5d2c739",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "graid",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
