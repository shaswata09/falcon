{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "541cc10f",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "e8932c1c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torch.nn.functional import normalize\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import clear_output\n",
        "import time  # Optional, to slow down updates a little"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd795bb1",
      "metadata": {},
      "source": [
        "# Path Declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ba1ba878",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "project_base_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
        "project_base_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c3afbec",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON/data/generation/yara/yara-rules_gpt.pkl'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_v1_generated_data_path = os.path.join(project_base_path, \"data/generation/yara/yara-rules_v1.pkl\")\n",
        "saved_v1_generated_data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd845c97",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/ANONYMOUS/projects/FALCON/data/generation/yara/yara-rules_llama_33.pkl'"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "saved_v2_generated_data_path = os.path.join(project_base_path, \"data/generation/yara/yara-rules_v2.pkl\")\n",
        "saved_v2_generated_data_path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1daf1533",
      "metadata": {},
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "4d632e4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "5e4f5c52",
      "metadata": {},
      "outputs": [],
      "source": [
        "open_ai_key = \"OPENAI_KEY\"\n",
        "os.environ['OPENAI_API_KEY'] = open_ai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec20aec3",
      "metadata": {},
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "014ec9d5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_from_pickle(file_path) -> dict:\n",
        "    \"\"\"\n",
        "    Loads data from a pickle file.\n",
        "\n",
        "    :param file_path: Path to the pickle file\n",
        "    :return: Loaded data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'rb') as file:\n",
        "            return pickle.load(file)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data from pickle: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "de3e3faf",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_first_n_elements(dictionary: dict, n: int) -> dict:\n",
        "    \"\"\"\n",
        "    Get the first n elements of a dictionary.\n",
        "\n",
        "    :param dictionary: The input dictionary\n",
        "    :param n: The number of elements to retrieve\n",
        "    :return: A dictionary with the first n elements\n",
        "    \"\"\"\n",
        "    return dict(list(dictionary.items())[:n])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "eb3d8810",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4588\n"
          ]
        }
      ],
      "source": [
        "# Load the data back from the pickle file\n",
        "loaded_v1_data = load_from_pickle(saved_v1_generated_data_path)\n",
        "print(len(loaded_v1_data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "7534dfe1",
      "metadata": {},
      "outputs": [],
      "source": [
        "yara_cti_sample_dict = get_first_n_elements(loaded_v1_data, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "77943529",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4587\n"
          ]
        }
      ],
      "source": [
        "# Load the data back from the pickle file\n",
        "loaded_v2_data = load_from_pickle(saved_v2_generated_data_path)\n",
        "print(len(loaded_v2_data.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "b37803a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'rule MSIETabularActivex\\n{\\n        meta:\\n                ref = \"CVE-2010-0805\"\\n                impact = 7\\n                hide = true\\n                author = \"@d3t0n4t0r\"\\n        strings:\\n                $cve20100805_1 = \"333C7BC4-460F-11D0-BC04-0080C7055A83\" nocase fullword\\n                $cve20100805_2 = \"DataURL\" nocase fullword\\n                $cve20100805_3 = \"true\"\\n        condition:\\n                ($cve20100805_1 and $cve20100805_3) or (all of them)\\n}': 'Rule Name\\n  MSIETabularActivex\\n\\nDescription\\n  This YARA rule detects a specific vulnerability (CVE-2010-0805) associated with an ActiveX control. The rule targets potentially malicious strings that could be used in exploit attempts related to this vulnerability.\\n\\nReference\\n  CVE-2010-0805\\n\\nIndicators / String Matches\\n  This rule matches the following strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $cve20100805_1\\t\"333C7BC4-460F-11D0-BC04-0080C7055A83\"\\tActiveX control CLSID\\n  $cve20100805_2\\t\"DataURL\"\\tPossible exploit-related term\\n  $cve20100805_3\\t\"true\"\\tPotential Boolean indicator used in exploitation\\n\\n  All string patterns use nocase and fullword modifiers, allowing detection regardless of case and requiring exact word matches.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  The ActiveX control CLSID ($cve20100805_1) and the Boolean indicator ($cve20100805_3) are both present.\\n\\n  Alternatively, if all strings ($cve20100805_1, $cve20100805_2, and $cve20100805_3) are found.',\n",
              " 'rule Contains_VBA_macro_code\\n{\\n\\tmeta:\\n\\t\\tauthor = \"evild3ad\"\\n\\t\\tdescription = \"Detect a MS Office document with embedded VBA macro code\"\\n\\t\\tdate = \"2016-01-09\"\\n\\t\\tfiletype = \"Office documents\"\\n\\n\\tstrings:\\n\\t\\t$officemagic = { D0 CF 11 E0 A1 B1 1A E1 }\\n\\t\\t$zipmagic = \"PK\"\\n\\n\\t\\t$97str1 = \"_VBA_PROJECT_CUR\" wide\\n\\t\\t$97str2 = \"VBAProject\"\\n\\t\\t$97str3 = { 41 74 74 72 69 62 75 74 00 65 20 56 42 5F } // Attribute VB_\\n\\n\\t\\t$xmlstr1 = \"vbaProject.bin\"\\n\\t\\t$xmlstr2 = \"vbaData.xml\"\\n\\n\\tcondition:\\n\\t\\t($officemagic at 0 and any of ($97str*)) or ($zipmagic at 0 and any of ($xmlstr*))\\n}': '    Rule Name\\n        Contains_VBA_macro_code\\n    \\n    Description\\n        This YARA rule is designed to detect Microsoft Office documents that contain embedded VBA macro code. Macros are often used by attackers to execute malicious actions in the context of Office applications. The rule checks both OLE and Open XML format documents for indications of VBA content.\\n    \\n    Indicators / String Matches\\n        This rule uses the following string patterns to identify potential VBA macro content:\\n    \\n        String ID\\tPattern\\t                        Notes\\n        $officemagic\\t{ D0 CF 11 E0 A1 B1 1A E1 }\\tOLE file format magic number\\n        $zipmagic\\t\"PK\"\\t                        ZIP file format magic number (indicative of Office Open XML)\\n        $97str1\\t    \"_VBA_PROJECT_CUR\" wide       \\tIdentifies VBA project storage in OLE documents\\n        $97str2\\t    \"VBAProject\"\\t                VBA project stream name\\n        $97str3\\t    { 41 74 74 72 69 62 75 74 00 65 20 56 42 5F }\\tRepresents \"Attribute VB_\"\\n        $xmlstr1\\t\"vbaProject.bin\"\\t            VBA project container file in ZIP format\\n        $xmlstr2\\t\"vbaData.xml\"\\t                XML file containing VBA data\\n    \\n    Condition Logic\\n        The rule triggers if:\\n    \\n        - The file is an OLE document (identified by $officemagic at offset 0) and contains any of the VBA-related patterns ($97str1, $97str2, or $97str3).\\n    \\n        - The file is a ZIP (Office Open XML) document (identified by $zipmagic at offset 0) and contains any of the XML-based VBA indicators ($xmlstr1 or $xmlstr2).',\n",
              " 'rule php_anuna\\n{\\n    meta:\\n        author      = \"Vlad https://github.com/vlad-s\"\\n        date        = \"2016/07/18\"\\n        description = \"Catches a PHP Trojan\"\\n    strings:\\n        $a = /<\\\\?php \\\\$[a-z]+ = \\'/\\n        $b = /\\\\$[a-z]+=explode\\\\(chr\\\\(\\\\([0-9]+[-+][0-9]+\\\\)\\\\)/\\n        $c = /\\\\$[a-z]+=\\\\([0-9]+[-+][0-9]+\\\\)/\\n        $d = /if \\\\(!function_exists\\\\(\\'[a-z]+\\'\\\\)\\\\)/\\n    condition:\\n        all of them\\n}': \"```\\nRule Name\\n  php_anuna\\n\\nDescription\\n  This YARA rule is designed to detect a specific PHP Trojan by identifying suspicious script patterns typical of malicious PHP code. The trojan employs obfuscation techniques such as variable assignment through code evaluation and uses checks for undefined functions.\\n\\nIndicators / String Matches\\n  This rule matches the following regular expressions:\\n\\n  String ID\\tPattern\\tNotes\\n  $a\\t/<\\\\?php \\\\$[a-z]+ = '/\\tDetects PHP code starting with variable assignment\\n  $b\\t/\\\\$[a-z]+=explode\\\\(chr\\\\(\\\\([0-9]+[-+][0-9]+\\\\)\\\\)/\\tDetects obfuscated explode calls\\n  $c\\t/\\\\$[a-z]+=\\\\([0-9]+[-+][0-9]+\\\\)/\\tDetects arithmetic operations in obfuscated variables\\n  $d\\t/if \\\\(!function_exists\\\\('[a-z]+'\\\\)\\\\)/\\tChecks for the use of function_exists in obfuscation\\n\\nCondition Logic\\n  The rule triggers if all of the specified string patterns ($a through $d) are found within the PHP file, indicating potential obfuscated malicious activity.\\n\\n```\",\n",
              " 'rule Powerkatz_DLL_Generic {\\n\\tmeta:\\n\\t\\tdescription = \"Detects Powerkatz - a Mimikatz version prepared to run in memory via Powershell (overlap with other Mimikatz versions is possible)\"\\n\\t\\tauthor = \"Florian Roth\"\\n\\t\\treference = \"PowerKatz Analysis\"\\n\\t\\tdate = \"2016-02-05\"\\n\\t\\tsuper_rule = 1\\n\\t\\tscore = 80\\n\\t\\thash1 = \"c20f30326fcebad25446cf2e267c341ac34664efad5c50ff07f0738ae2390eae\"\\n\\t\\thash2 = \"1e67476281c1ec1cf40e17d7fc28a3ab3250b474ef41cb10a72130990f0be6a0\"\\n\\t\\thash3 = \"49e7bac7e0db87bf3f0185e9cf51f2539dbc11384fefced465230c4e5bce0872\"\\n\\tstrings:\\n\\t\\t$s1 = \"%3u - Directory \\'%s\\' (*.kirbi)\" fullword wide\\n\\t\\t$s2 = \"%*s  pPublicKey         : \" fullword wide\\n\\t\\t$s3 = \"ad_hoc_network_formed\" fullword wide\\n\\t\\t$s4 = \"<3 eo.oe ~ ANSSI E>\" fullword wide\\n\\t\\t$s5 = \"\\\\\\\\*.kirbi\" fullword wide\\n\\n\\t\\t$c1 = \"kuhl_m_lsadump_getUsersAndSamKey ; kull_m_registry_RegOpenKeyEx SAM Accounts (0x%08x)\" fullword wide\\n\\t\\t$c2 = \"kuhl_m_lsadump_getComputerAndSyskey ; kuhl_m_lsadump_getSyskey KO\" fullword wide\\n\\tcondition:\\n\\t\\t( uint16(0) == 0x5a4d and filesize < 1000KB and 1 of them ) or 2 of them\\n}': '```\\nRule Name\\n  Powerkatz_DLL_Generic\\n\\nDescription\\n  This YARA rule is crafted to detect Powerkatzâ€”a variant of the credential-stealing tool Mimikatz, specifically adapted to operate within memory via PowerShell scripts. This rule may overlap with other detections for various Mimikatz versions.\\n\\nReference\\n  PowerKatz Analysis\\n\\nIndicators / String Matches\\n  This rule matches the following wide (Unicode) strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $s1\\t\"%3u - Directory \\'%s\\' (*.kirbi)\"\\tIndicates location of Kerberos ticket files\\n  $s2\\t\"%*s  pPublicKey         : \"\\tRelated to cryptographic operations\\n  $s3\\t\"ad_hoc_network_formed\"\\tPossibly related to network operations\\n  $s4\\t\"<3 eo.oe ~ ANSSI E>\"\\tPotential marker or signature string\\n  $s5\\t\"\\\\\\\\*.kirbi\"\\tTargets Kerberos ticket files\\n\\n  Control Pattern ID\\tPattern\\tNotes\\n  $c1\\t\"kuhl_m_lsadump_getUsersAndSamKey ; kull_m_registry_RegOpenKeyEx SAM Accounts (0x%08x)\"\\tFunction to dump user and SAM keys\\n  $c2\\t\"kuhl_m_lsadump_getComputerAndSyskey ; kuhl_m_lsadump_getSyskey KO\"\\tFunction for obtaining system keys\\n\\n  All string patterns use fullword and wide modifiers, meaning they match exact full Unicode words.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  - The file has a valid DOS MZ header (uint16(0) == 0x5A4D) and the file size is less than 1000KB, and at least one of the specified string patterns ($s1 through $c2) is found.\\n\\n  OR\\n\\n  - At least two of the specified string patterns ($s1 through $c2) are found, regardless of file size or header check.\\n\\nKnown File Hashes\\n  SHA256: c20f30326fcebad25446cf2e267c341ac34664efad5c50ff07f0738ae2390eae\\n  SHA256: 1e67476281c1ec1cf40e17d7fc28a3ab3250b474ef41cb10a72130990f0be6a0\\n  SHA256: 49e7bac7e0db87bf3f0185e9cf51f2539dbc11384fefced465230c4e5bce0872\\n```\\n',\n",
              " 'rule RomeoCharlie\\n{\\n\\tmeta:\\n\\t\\tcopyright = \"2015 Novetta Solutions\"\\n\\t\\tauthor = \"Novetta Threat Research & Interdiction Group - trig@novetta.com\"\\n\\t\\tSource = \"a82108ef7115931b3fbe1fab99448c4139e22feda27c1b1d29325710671154e8\"\\n\\n\\tstrings:\\n\\t\\t$auth1 = \"Success - Accept Auth\"\\n\\t\\t$auth2 = \"Fail - Accept Auth\"\\n\\n\\t/*\\n\\t\\t81 E3 FF FF 00 00  and     ebx, 0FFFFh\\n\\t\\t8B EB              mov     ebp, ebx\\n\\t\\t57                 push    edi\\n\\t\\tC1 EE 10           shr     esi, 10h\\n\\t\\t81 E5 FF FF 00 00  and     ebp, 0FFFFh\\n\\t\\t8B FE              mov     edi, esi\\n\\t\\t8B C5              mov     eax, ebp\\n\\t\\t81 E7 FF FF 00 00  and     edi, 0FFFFh\\n\\t\\tC1 E0 10           shl     eax, 10h\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\t0B C7              or      eax, edi\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\t50                 push    eax             ; _DWORD\\n\\t\\t68 10 14 11 71     push    offset sub_71111410; _DWORD\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\t6A 00              push    0               ; _DWORD\\n\\t\\tFF 15 5C 8E 12 71  call    CreateThread_0\\n\\t\\tC1 E7 10           shl     edi, 10h\\n\\t*/\\n\\n\\t$startupRelayThreads = {81 ?? FF FF 00 00 8B ?? 5? C1 ?? 10 81 ?? FF FF 00 00 8B ?? 8B ?? 81 ?? FF FF 00 00 C1 ?? 10 6A 00 0B ?? 6A 00 \\t50 68 [4] 6A 00 6A 00 FF 15 [4] C1 ?? 10 }\\n\\n\\t/*\\n\\tsource: 641808833ad34f2e5143001c8147d779dbfd2a80a80ce0cfc81474d422882adb\\n\\t\\t25 00 20 00 00     and     eax, 2000h\\n\\t\\t3D 00 20 00 00     cmp     eax, 2000h\\n\\t\\t0F 94 C1           setz    cl\\n\\t\\t81 E2 80 00 00 00  and     edx, 80h\\n\\t\\t33 C0              xor     eax, eax\\n\\t\\t80 FA 80           cmp     dl, 80h\\n\\t\\t0F 94 C0           setz    al\\n\\t\\t03 C8              add     ecx, eax\\n\\t\\t33 D2              xor     edx, edx\\n\\t\\t83 F9 01           cmp     ecx, 1\\n\\t*/\\n\\n\\t$crypto = {2? 00 20 00 00 3? 00 20 00 00 0F [2] 81 ?? 80 00 00 00 33 ?? 80 ?? 80 0F [2] 03 ?? 33 ?? 83 ?? 01 }\\n\\n\\tcondition:\\n\\t\\tall of ($auth*) \\n\\t\\tor $startupRelayThreads in ((pe.sections[pe.section_index(\".text\")].raw_data_offset)..(pe.sections[pe.section_index(\".text\")].raw_data_offset + pe.sections[pe.section_index(\".text\")].raw_data_size))\\n\\t\\tor $crypto in ((pe.sections[pe.section_index(\".text\")].raw_data_offset)..(pe.sections[pe.section_index(\".text\")].raw_data_offset + pe.sections[pe.section_index(\".text\")].raw_data_size))\\n}': 'Rule Name  \\n  RomeoCharlie\\n\\nDescription  \\n  This YARA rule detects specific patterns associated with certain malware samples analyzed by Novetta. The rule includes string matches that indicate authentication success or failure, as well as patterns for a known technique involving initiation of relay threads and cryptographic operations within a PE file\\'s .text section. This rule helps identify these techniques by matching either of the string patterns or the known byte patterns within .text sections commonly used in malicious binaries.\\n\\nReference  \\n  There is no direct public reference provided for this YARA rule, but it is attributed to Novetta\\'s Threat Research & Interdiction Group.\\n\\nIndicators / String Matches  \\n  The rule matches the following string and byte patterns:\\n\\n  String ID | Pattern                  | Notes  \\n  $auth1    | \"Success - Accept Auth\"  | Indicates successful authentication  \\n  $auth2    | \"Fail - Accept Auth\"     | Indicates authentication failure  \\n\\n  Byte Pattern ID | Pattern Description  \\n  $startupRelayThreads | Matches specific byte pattern for starting relay threads, typical of malware operations.  \\n  $crypto             | Matches specific byte pattern associated with certain cryptographic operations found in malware.\\n\\nCondition Logic  \\n  The rule triggers if any of the following conditions are met:\\n\\n  - Either of the authentication strings ($auth1 or $auth2) are present.\\n  - The $startupRelayThreads byte pattern is found within the .text section of the PE file.\\n  - The $crypto byte pattern is found within the .text section of the PE file.\\n\\nKnown File Hash  \\n  The rule was derived using a known sample hash:  \\n  SHA256: a82108ef7115931b3fbe1fab99448c4139e22feda27c1b1d29325710671154e8',\n",
              " 'rule TreasureHunt\\n  {\\n    meta:\\n      author = \"Minerva Labs\"\\n      ref =\"http://www.minerva-labs.com/#!Cybercriminals-Adopt-the-Mossad-Emblem/c7a5/573da2d60cf2f90ca6f6e3ed\"\\n      date = \"2016/06\"\\n      maltype = \"Point of Sale (POS) Malware\"\\n      filetype = \"exe\"\\n\\n    strings:\\n      $a = \"treasureHunter.pdb\"\\n      $b = \"jucheck\"\\n      $c = \"cmdLineDecrypted\"\\n\\n    condition:\\n      all of them\\n}': '```\\nRule Name\\n  TreasureHunt\\n\\nDescription\\n  This YARA rule aims to identify a specific Point of Sale (POS) malware referred to as \"TreasureHunt.\" It detects executables containing specific strings that suggest malware functionality related to command-line decryption and possibly masquerading as a legitimate Java update checker (jucheck). The inclusion of a PDB path string indicates potential association with debugging or development contexts.\\n\\nReference\\n  Minerva Labs Report\\n  Full Report: http://www.minerva-labs.com/#!Cybercriminals-Adopt-the-Mossad-Emblem/c7a5/573da2d60cf2f90ca6f6e3ed\\n\\nIndicators / String Matches\\n  This rule matches the following strings:\\n\\n  String ID\\tPattern\\t                      Notes\\n  $a\\t\"treasureHunter.pdb\"\\t      PDB file path, possibly for debugging\\n  $b\\t\"jucheck\"\\t                  Potential impersonation of Java update checker\\n  $c\\t\"cmdLineDecrypted\"\\t          Functionality related to command-line decryption\\n\\n  All string patterns are considered essential for detection.\\n\\nCondition Logic\\n  The rule triggers if all of the specified string patterns ($a, $b, and $c) are found within the file, indicating the presence of the TreasureHunt malware.\\n\\n```',\n",
              " 'rule HKTL_NET_GUID_CSharpSetThreadContext {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/djhohnstein/CSharpSetThreadContext\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"a1e28c8c-b3bd-44de-85b9-8aa7c18a714d\" ascii nocase wide\\n        $typelibguid1 = \"87c5970e-0c77-4182-afe2-3fe96f785ebb\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '```\\nRule Name\\n  HKTL_NET_GUID_CSharpSetThreadContext\\n\\nDescription\\n  This YARA rule is designed to detect C# red/black-team tools by identifying specific type library GUIDs associated with the CSharpSetThreadContext repository. The rule targets tools that may use these typelib GUIDs for malicious or penetration testing purposes.\\n\\nReference\\n  CSharpSetThreadContext Repository\\n  Full Repository: https://github.com/djhohnstein/CSharpSetThreadContext\\n\\nIndicators / String Matches\\n  This rule matches the following wide (Unicode) strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $typelibguid0\\t\"a1e28c8c-b3bd-44de-85b9-8aa7c18a714d\"\\tType library GUID used in CSharpSetThreadContext\\n  $typelibguid1\\t\"87c5970e-0c77-4182-afe2-3fe96f785ebb\"\\tAnother type library GUID used in CSharpSetThreadContext\\n\\n  Both string patterns use ascii, nocase, and wide modifiers, meaning they match ASCII as well as Unicode strings in a case-insensitive manner.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  The file has a valid DOS MZ header (uint16(0) == 0x5A4D).\\n\\n  The file also has a valid PE header signature (uint32(uint32(0x3C)) == 0x00004550).\\n\\n  Any of the specified string patterns ($typelibguid0 or $typelibguid1) are found.\\n```\\n',\n",
              " 'rule HKTL_NET_GUID_DLL_Injection {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/ihack4falafel/DLL-Injection\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"3d7e1433-f81a-428a-934f-7cc7fcf1149d\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '    Rule Name\\n      HKTL_NET_GUID_DLL_Injection\\n\\n    Description\\n      This YARA rule is designed to detect C# injection tools used by red and black team operations by identifying a specific typelib GUID. The rule targets tools that manipulate or inject themselves into processes using a specific typelib GUID, potentially indicating malicious activities associated with DLL injection techniques.\\n\\n    Reference\\n      GitHub - DLL Injection \\n      Full Reference: https://github.com/ihack4falafel/DLL-Injection\\n\\n    Indicators / String Matches\\n      This rule matches the following strings with specific properties:\\n\\n      String ID\\tPattern\\tNotes\\n      $typelibguid0\\t\"3d7e1433-f81a-428a-934f-7cc7fcf1149d\"\\tTypelib GUID related to DLL injection\\n\\n      The pattern uses ascii, nocase, and wide modifiers, allowing for flexible detection of the GUID in different encodings and cases.\\n\\n    Condition Logic\\n      The rule triggers if:\\n\\n      The file starts with a valid DOS MZ header (uint16(0) == 0x5A4D).\\n      \\n      The file has a valid PE header located at the offset specified in the DOS header (uint32(uint32(0x3C)) == 0x00004550).\\n\\n      Any of the specified string patterns ($typelibguid0) are found.',\n",
              " 'rule HKTL_NET_GUID_LimeUSB_Csharp {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/NYAN-x-CAT/LimeUSB-Csharp\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"94ea43ab-7878-4048-a64e-2b21b3b4366d\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '    Rule Name\\n      HKTL_NET_GUID_LimeUSB_Csharp\\n\\n    Description\\n      This YARA rule is designed to identify C# tools often associated with red team or black hat operations, specifically through the detection of a Type Library GUID string within binaries. The rule targets deployments or tools similar to those found in the LimeUSB-Csharp repository, suggesting potential misuse for unauthorized purposes.\\n\\n    Reference\\n      LimeUSB-Csharp\\n      Full Reference: https://github.com/NYAN-x-CAT/LimeUSB-Csharp\\n\\n    Indicators / String Matches\\n      This rule matches the following strings:\\n\\n      String ID \\tPattern\\tNotes\\n      $typelibguid0\\t\"94ea43ab-7878-4048-a64e-2b21b3b4366d\"\\tType Library GUID associated with C# tools\\n\\n      The match is case-insensitive and supports both ASCII and wide (Unicode) formats.\\n\\n    Condition Logic\\n      The rule triggers if:\\n\\n      The file contains a valid DOS MZ header (uint16(0) == 0x5A4D).\\n\\n      The file contains a valid PE header signature (uint32(uint32(0x3C)) == 0x00004550).\\n\\n      Any of the specified string patterns are found.',\n",
              " 'rule HKTL_NET_GUID_Ladon {\\n    meta:\\n        description = \"Detects c# red/black-team tools via typelibguid\"\\n        reference = \"https://github.com/k8gege/Ladon\"\\n        author = \"Arnim Rupp\"\\n        date = \"2020-12-13\"\\n    strings:\\n        $typelibguid0 = \"c335405f-5df2-4c7d-9b53-d65adfbed412\" ascii nocase wide\\n    condition:\\n        (uint16(0) == 0x5A4D and uint32(uint32(0x3C)) == 0x00004550) and any of them\\n}': '```plaintext\\nRule Name\\n  HKTL_NET_GUID_Ladon\\n\\nDescription\\n  This YARA rule is designed to detect the presence of specific C# red/black-team tools via their typelib GUID. It identifies potentially malicious tools used for post-exploitation activities by analyzing the typelib GUID embedded within executables. The presence of these tools may indicate unauthorized activities related to red teaming or black hat operations.\\n\\nReference\\n  Ladon Tool Repository\\n  Source: https://github.com/k8gege/Ladon\\n\\nIndicators / String Matches\\n  This rule matches the following strings:\\n\\n  String ID\\tPattern\\tNotes\\n  $typelibguid0\\t\"c335405f-5df2-4c7d-9b53-d65adfbed412\"\\tTypelib GUID used in C# tools\\n\\n  The string patterns are checked with ascii, nocase, and wide modifiers, allowing for flexible matching of typelibs.\\n\\nCondition Logic\\n  The rule triggers if:\\n\\n  The file has a valid MZ header (uint16(0) == 0x5A4D).\\n  \\n  The file has a valid PE header signature (uint32(uint32(0x3C)) == 0x00004550).\\n\\n  Any of the specified string patterns ($typelibguid0) are found.\\n```'}"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yara_cti_sample_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "aff9842a",
      "metadata": {},
      "outputs": [],
      "source": [
        "yaras, ctis = zip(*yara_cti_sample_dict.items())\n",
        "yaras = list(yaras)\n",
        "ctis = list(ctis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "22b56710",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(yaras), len(ctis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "07358c99",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_cti_yara_data_to_training_data(data: list[dict]) -> list[tuple]:\n",
        "    \"\"\"\n",
        "    Format the CTI yara data into training data.\n",
        "\n",
        "    :param data: The data to format\n",
        "    :return: Formatted training data\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    for dataset in data:\n",
        "        for key, value in dataset.items():\n",
        "            training_data.append((key, value))\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "2a9524da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9175\n"
          ]
        }
      ],
      "source": [
        "# Sample Dataset Format (list of (anchor, positive) sentence pairs)\n",
        "full_dataset = format_cti_yara_data_to_training_data([loaded_v1_data, loaded_v2_data])\n",
        "print(len(full_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "825047d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_10_test_samples(training_data: list[tuple], test_pairs: dict) -> list[tuple]:\n",
        "    # Extract all test keys and values into sets for quick lookup\n",
        "    test_keys = set(test_pairs.keys())\n",
        "    test_values = set(test_pairs.values())\n",
        "    \n",
        "    # Filter training data\n",
        "    filtered_data = [(key, value) for key, value in training_data if key not in test_keys and value not in test_values]\n",
        "    \n",
        "    return filtered_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "d4de188f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9155\n"
          ]
        }
      ],
      "source": [
        "# Sample Dataset Format (list of (anchor, positive) sentence pairs)\n",
        "full_dataset = remove_10_test_samples(full_dataset, yara_cti_sample_dict)\n",
        "print(len(full_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "7699b4ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split into training and testing sets (80% train, 20% test)\n",
        "train_pairs, test_pairs = train_test_split(full_dataset, test_size=0.1, random_state=SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67114ad1",
      "metadata": {},
      "source": [
        "# Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "fdd1300f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom Dataset\n",
        "class ContrastiveDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor, positive = self.data[idx]\n",
        "        encoded = self.tokenizer([anchor, positive], padding=\"max_length\", truncation=True,\n",
        "                                 max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "        return {\n",
        "            \"input_ids_a\": encoded[\"input_ids\"][0],\n",
        "            \"attention_mask_a\": encoded[\"attention_mask\"][0],\n",
        "            \"input_ids_b\": encoded[\"input_ids\"][1],\n",
        "            \"attention_mask_b\": encoded[\"attention_mask\"][1],\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "3a0c3aa3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bi-Encoder Model\n",
        "class SentenceEncoder(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super().__init__()\n",
        "        self.encoder = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state[:, 0]  # CLS token\n",
        "        return nn.functional.normalize(embeddings, p=2, dim=1)  # Normalize for cosine similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "be4e3149",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Contrastive Loss (InfoNCE / NT-Xent)\n",
        "def contrastive_loss(emb_a, emb_b, temperature=0.05):\n",
        "    similarity_matrix = torch.matmul(emb_a, emb_b.T) / temperature\n",
        "    labels = torch.arange(len(emb_a)).to(emb_a.device)\n",
        "    return nn.CrossEntropyLoss()(similarity_matrix, labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a804e3",
      "metadata": {},
      "source": [
        "# Scaling Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "13bb90cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dot_product_matrix(matrix: torch.Tensor):\n",
        "    \"\"\"\n",
        "    Computes statistics for the principal diagonal and off-diagonal values of a dot product matrix.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): A square 2D tensor (dot product matrix).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[dict, dict]: (diagonal_stats, off_diagonal_stats)\n",
        "    \"\"\"\n",
        "    assert matrix.ndim == 2 and matrix.shape[0] == matrix.shape[1], \"Matrix must be square\"\n",
        "\n",
        "    diag_vals = torch.diag(matrix)\n",
        "    all_vals = matrix.flatten()\n",
        "    off_diag_mask = ~torch.eye(matrix.size(0), dtype=torch.bool, device=matrix.device)\n",
        "    off_diag_vals = matrix[off_diag_mask]\n",
        "\n",
        "    def stats(tensor):\n",
        "        return {\n",
        "            \"mean\": tensor.mean().item(),\n",
        "            \"max\": tensor.max().item(),\n",
        "            \"min\": tensor.min().item(),\n",
        "            \"std\": tensor.std(unbiased=False).item(),  # population std\n",
        "        }\n",
        "\n",
        "    return stats(diag_vals), stats(off_diag_vals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "43ec092c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "def compute_dot_product_matrix_openai(test_yaras, test_ctis, batch_size=50):\n",
        "    embedder = OpenAIEmbeddings()  # Uses text-embedding-ada-002 by default\n",
        "\n",
        "    # Step 1: Get embeddings for all yara rules\n",
        "    yara_embeddings = []\n",
        "    for i in range(0, len(test_yaras), batch_size):\n",
        "        batch = test_yaras[i:i + batch_size]\n",
        "        yara_embeddings.extend(embedder.embed_documents(batch))  # List of vectors\n",
        "\n",
        "    yara_embeddings = np.array(yara_embeddings)  # Shape: (N, D)\n",
        "    yara_embeddings_norm = np.linalg.norm(yara_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    # Step 2: Compute batched dot products with CTIs\n",
        "    dot_product_matrix = []\n",
        "\n",
        "    for i in range(0, len(test_ctis), batch_size):\n",
        "        batch = test_ctis[i:i + batch_size]\n",
        "        cti_embeddings = embedder.embed_documents(batch)\n",
        "        cti_embeddings = np.array(cti_embeddings)\n",
        "        cti_embeddings_norm = np.linalg.norm(cti_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "        # Normalize and compute dot product\n",
        "        sim_matrix = np.dot(cti_embeddings, yara_embeddings.T) / (\n",
        "            cti_embeddings_norm @ yara_embeddings_norm.T\n",
        "        )\n",
        "        dot_product_matrix.append(sim_matrix)\n",
        "\n",
        "    dot_product_matrix = np.vstack(dot_product_matrix)  # Final shape: (len(test_ctis), len(test_yaras))\n",
        "    return dot_product_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84239265",
      "metadata": {},
      "source": [
        "## 10 Validation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf3f96f7",
      "metadata": {},
      "source": [
        "### Run - 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b036d7b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "diag_stats, off_diag_stats = analyze_dot_product_matrix(dot_product_matrix)\n",
        "\n",
        "print(\"Diagonal Stats:\", diag_stats)\n",
        "print(\"Off-Diagonal Stats:\", off_diag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed8e35c6",
      "metadata": {},
      "source": [
        "### Run - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b113bce",
      "metadata": {},
      "outputs": [],
      "source": [
        "diag_stats, off_diag_stats = analyze_dot_product_matrix(dot_product_matrix)\n",
        "\n",
        "print(\"Diagonal Stats:\", diag_stats)\n",
        "print(\"Off-Diagonal Stats:\", off_diag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abcda13e",
      "metadata": {},
      "source": [
        "### Run - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08bc0367",
      "metadata": {},
      "outputs": [],
      "source": [
        "diag_stats, off_diag_stats = analyze_dot_product_matrix(dot_product_matrix)\n",
        "\n",
        "print(\"Diagonal Stats:\", diag_stats)\n",
        "print(\"Off-Diagonal Stats:\", off_diag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4146fd8",
      "metadata": {},
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888f92d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_yaras = [i[0] for i in test_pairs]\n",
        "test_ctis = [i[1] for i in test_pairs]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4e9730",
      "metadata": {},
      "source": [
        "### Run - 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76aec5e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "dot_product_matrix_test = compute_dot_product_matrix_batched(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_yaras=test_yaras,\n",
        "    test_ctis=test_ctis,\n",
        "    batch_size=256\n",
        ")\n",
        "\n",
        "diag_stats, off_diag_stats = analyze_dot_product_matrix(dot_product_matrix_test)\n",
        "\n",
        "print(\"Diagonal Stats:\", diag_stats)\n",
        "print(\"Off-Diagonal Stats:\", off_diag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25623f2c",
      "metadata": {},
      "source": [
        "### Run - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1682fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "dot_product_matrix_test = compute_dot_product_matrix_batched(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_yaras=test_yaras,\n",
        "    test_ctis=test_ctis,\n",
        "    batch_size=256\n",
        ")\n",
        "\n",
        "diag_stats, off_diag_stats = analyze_dot_product_matrix(dot_product_matrix_test)\n",
        "\n",
        "print(\"Diagonal Stats:\", diag_stats)\n",
        "print(\"Off-Diagonal Stats:\", off_diag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cfbfe72b",
      "metadata": {},
      "source": [
        "### Run - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "788fe958",
      "metadata": {},
      "outputs": [],
      "source": [
        "dot_product_matrix_test = compute_dot_product_matrix_batched(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    test_yaras=test_yaras,\n",
        "    test_ctis=test_ctis,\n",
        "    batch_size=256\n",
        ")\n",
        "\n",
        "diag_stats, off_diag_stats = analyze_dot_product_matrix(dot_product_matrix_test)\n",
        "\n",
        "print(\"Diagonal Stats:\", diag_stats)\n",
        "print(\"Off-Diagonal Stats:\", off_diag_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d979c2e",
      "metadata": {},
      "source": [
        "# Semantic Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "181dfda5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def evaluate_similarity_with_auto_threshold_numpy(dot_product_matrix: np.ndarray):\n",
        "    \"\"\"\n",
        "    Evaluates diagonal recall and best F1-score based on thresholded sigmoid scores\n",
        "    using OpenAI-generated NumPy dot-product matrix.\n",
        "\n",
        "    Args:\n",
        "        dot_product_matrix (np.ndarray): Square similarity matrix (N x N)\n",
        "\n",
        "    Returns:\n",
        "        dict: {\n",
        "            'recall_diag': float,\n",
        "            'f1_best': float,\n",
        "            'best_threshold': float,\n",
        "            'sigmoid_min': float,\n",
        "            'sigmoid_max': float,\n",
        "        }\n",
        "    \"\"\"\n",
        "    assert dot_product_matrix.ndim == 2 and dot_product_matrix.shape[0] == dot_product_matrix.shape[1], \\\n",
        "        \"Input must be a square matrix.\"\n",
        "\n",
        "    N = dot_product_matrix.shape[0]\n",
        "\n",
        "    # Apply sigmoid to scores\n",
        "    sigmoid_scores = 1 / (1 + np.exp(-dot_product_matrix))\n",
        "\n",
        "    # Diagonal Recall: how often the highest score is at the correct (diagonal) position\n",
        "    recall_diag = np.mean([np.argmax(dot_product_matrix[i]) == i for i in range(N)])\n",
        "\n",
        "    # Prepare labels and scores\n",
        "    labels = []\n",
        "    flat_scores = []\n",
        "\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            labels.append(1 if i == j else 0)\n",
        "            flat_scores.append(sigmoid_scores[i, j])\n",
        "\n",
        "    # Search for best threshold to maximize F1\n",
        "    thresholds = np.linspace(min(flat_scores), max(flat_scores), num=100)\n",
        "    best_f1 = 0.0\n",
        "    best_threshold = 0.0\n",
        "\n",
        "    for t in thresholds:\n",
        "        preds = [1 if s >= t else 0 for s in flat_scores]\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = t\n",
        "\n",
        "    return {\n",
        "        \"recall_diag\": recall_diag,\n",
        "        \"f1_best\": best_f1,\n",
        "        \"best_threshold\": best_threshold,\n",
        "        \"sigmoid_min\": min(flat_scores),\n",
        "        \"sigmoid_max\": max(flat_scores),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "c6dab534",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_yaras = [i[0] for i in test_pairs]\n",
        "test_ctis = [i[1] for i in test_pairs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "50611d7e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(916, 916)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_yaras), len(test_ctis)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d29d1f4e",
      "metadata": {},
      "source": [
        "## Pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "4cff6898",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recall_diag: 0.9094\n",
            "f1_best: 0.6256\n",
            "best_threshold: 0.7089\n",
            "sigmoid_min: 0.6594\n",
            "sigmoid_max: 0.7199\n"
          ]
        }
      ],
      "source": [
        "dot_matrix = compute_dot_product_matrix_openai(test_yaras, test_ctis)\n",
        "metrics = evaluate_similarity_with_auto_threshold_numpy(dot_matrix)\n",
        "\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94918008",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "graid",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
