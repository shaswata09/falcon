{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads a PDF file and returns its extracted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import openai\n",
    "from PyPDF2 import PdfReader  \n",
    "\n",
    "def read_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Reads a PDF file and returns its extracted text.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file.\n",
    "        \n",
    "    Returns:\n",
    "        str: Combined text from all pages in the PDF.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as file:\n",
    "            reader = PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rule_from_description(description, rule_type, api_key, model=\"gpt-3.5-turbo\", max_prompt_chars=2000):\n",
    "    \"\"\"\n",
    "    Uses the OpenAI ChatGPT API to generate a rule (YARA or Snort) based on the provided description.\n",
    "    \n",
    "    Args:\n",
    "        description (str): Text extracted from the PDF.\n",
    "        rule_type (str): The type of rule to generate (\"YARA\" or \"Snort\").\n",
    "        api_key (str): Your OpenAI API key.\n",
    "        model (str): OpenAI model to use (default: gpt-3.5-turbo).\n",
    "        max_prompt_chars (int): Maximum number of characters from the description to include.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated rule text.\n",
    "    \"\"\"\n",
    "    openai.api_key = api_key\n",
    "    \n",
    "    # Limit the description length if too long\n",
    "    if len(description) > max_prompt_chars:\n",
    "        description = description[:max_prompt_chars] + \"\\n\\n[Description truncated due to length]\"\n",
    "    \n",
    "    rule_type_lower = rule_type.strip().lower()\n",
    "    \n",
    "    if rule_type_lower == \"yara\":\n",
    "        prompt = f\"\"\"\n",
    "I have a description for a YARA rule below:\n",
    "--------------------------------------------------\n",
    "{description}\n",
    "--------------------------------------------------\n",
    "Please generate a complete and valid YARA rule based on this description. The rule should include a proper rule header, string definitions, conditions, and comments explaining each part of the rule.\n",
    "        \"\"\"\n",
    "    elif rule_type_lower == \"snort\":\n",
    "        prompt = f\"\"\"\n",
    "I have a description for a Snort rule below:\n",
    "--------------------------------------------------\n",
    "{description}\n",
    "--------------------------------------------------\n",
    "Please generate a complete and valid Snort rule based on this description. The rule should include all necessary fields (such as the rule header, options, protocol details) along with comments explaining the detection logic.\n",
    "        \"\"\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported rule type. Please choose either 'YARA' or 'Snort'.\")\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a cybersecurity expert with expertise in creating both YARA and Snort rules.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    print(\"Sending API request to OpenAI...\")\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.2,  \n",
    "            max_tokens=800    \n",
    "        )\n",
    "        print(\"API response received.\")\n",
    "        return response.choices[0].message[\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the API call: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up directories for PDF description files and output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place your PDF description files in the 'C:/Users/azimb/Downloads/snortpdf' directory.\n",
      "Generated rules will be saved in the 'C:/Users/azimb/Downloads/snort3' directory.\n"
     ]
    }
   ],
   "source": [
    "input_dir = r\"Your input directory path\"\n",
    "output_dir = r\"Your output directory path\"\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Place your PDF description files in the '{input_dir}' directory.\")\n",
    "print(f\"Generated rules will be saved in the '{output_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using rule type: Snort\n"
     ]
    }
   ],
   "source": [
    "# Hardcode your OpenAI API key here\n",
    "api_key = \"OPenAI_API_KEY\"  \n",
    "\n",
    "# Set the desired rule type (either \"YARA\" or \"Snort\")\n",
    "default_rule_type = \"Snort\"\n",
    "rule_type = default_rule_type  # Change to \"SNORT\" if needed\n",
    "\n",
    "print(f\"Using rule type: {rule_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each PDF file and generate the corresponding rule.\n",
    "pdf_files = glob.glob(os.path.join(input_dir, \"*.pdf\"))\n",
    "\n",
    "if not pdf_files:\n",
    "    print(f\"No PDF files found in {input_dir}. Please add PDF description files to proceed.\")\n",
    "else:\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\nProcessing file: {pdf_file}\")\n",
    "        description = read_pdf(pdf_file)\n",
    "        if not description.strip():\n",
    "            print(f\"Warning: No text extracted from {pdf_file}. Skipping file.\")\n",
    "            continue\n",
    "        \n",
    "        rule_output = generate_rule_from_description(description, rule_type, api_key)\n",
    "        if rule_output is None:\n",
    "            print(f\"Failed to generate rule for {pdf_file}.\")\n",
    "            continue\n",
    "        \n",
    "        base_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}_{rule_type}_rule.txt\")\n",
    "        try:\n",
    "            with open(output_file, \"w\") as f:\n",
    "                f.write(rule_output)\n",
    "            print(f\"{rule_type} rule generated and saved to: {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error writing output to {output_file}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
